{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import data_utils\n",
    "import model\n",
    "import training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача - улучшение качества записи речи. На вход подаётся запись речи, содержащая шумы, а на выходе ожидается запись без шумов.\n",
    "\n",
    "Для решения этой задачи применялись генеративно-состязательные сети, состоящие из генератора, вычисляющего решение и дискриминатора, оценивающего его. При этом в задаче очищения речи существуют эталонные решения и метрики, позволяющие оценить сходство решения с эталоном, и оценка решения генератором не соответствует метрикам. Идея MetricGAN - вместо классификации решений на образцовые и сгенерированные обучить генератор приближать целевую метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном эксперименте уменьшенный вариант модели из статьи обучается на задаче восстановления записи речи. Используется датасет LibriSpeech и четыре вида шума из датасета DEMAND. Как и в статье, шум добавляется с отношением сигнал-шум от -8дб до 8дб с шагом 4 дб. Для оценки используется метрика STOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "ls_speaker_dirs = list((DATA_PATH / 'train-clean-100/LibriSpeech/train-clean-100/').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train_size = int(len(ls_speaker_dirs) * .6)\n",
    "ls_val_size = int(len(ls_speaker_dirs) * .2)\n",
    "ls_train_dirs = ls_speaker_dirs[:ls_train_size]\n",
    "ls_val_dirs = ls_speaker_dirs[ls_train_size:ls_train_size + ls_val_size]\n",
    "ls_test_dirs = ls_speaker_dirs[ls_train_size + ls_val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMAND_DIR = DATA_PATH / 'DEMAND'\n",
    "DEMAND_TYPES = 'NPARK', 'OOFFICE', 'PSTATION', 'SPSQUARE'\n",
    "DEMAND_TYPE_DIRS = [DEMAND_DIR / type_name for type_name in DEMAND_TYPES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = data_utils.DemandNoiser(DEMAND_TYPE_DIRS, np.linspace(-8, 8, 5))\n",
    "\n",
    "train_ds = data_utils.LibreSpeechDataset(ls_train_dirs, noiser)\n",
    "val_ds = data_utils.LibreSpeechDataset(ls_val_dirs, noiser, random_noise=False)\n",
    "test_ds = data_utils.LibreSpeechDataset(ls_test_dirs, noiser, random_noise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку при обучении на всех данных эпоха занимает слишком много времени, используются случайные подмножества тренировочной и валидационной выборок. Тренировочное подмножество каждый раз меняется, чтобы избежать переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSubsetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_dataset, n, fix):\n",
    "        super().__init__()\n",
    "        self.source_dataset = source_dataset\n",
    "        self.subset = random.sample(list(range(len(source_dataset))), n) if fix else None\n",
    "        self.fix = fix\n",
    "        self.n = n\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index >= self.n:\n",
    "            raise IndexError\n",
    "        if self.fix:\n",
    "            return self.source_dataset[index]\n",
    "        return self.source_dataset[random.randint(0, len(self.source_dataset) - 1)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.MetricGenerator().to(device)\n",
    "disc = model.MetricDiscriminator().to(device)\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters())\n",
    "disc_opt = torch.optim.Adam(disc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [21:14<00:00,  1.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:49<00:00,  2.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [10:14<00:00,  2.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:43<00:00,  2.42it/s]\n",
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 tr_disc_loss: 0.0271 val_disc_loss: 0.0117 tr_gen_loss: 0.0093 val_gen_loss: 0.0066, gen_stoi: 0.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [21:16<00:00,  1.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:50<00:00,  2.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [09:50<00:00,  2.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:38<00:00,  2.53it/s]\n",
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 tr_disc_loss: 0.0246 val_disc_loss: 0.0053 tr_gen_loss: 0.3442 val_gen_loss: 0.3383, gen_stoi: 0.6372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [20:53<00:00,  1.00s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:48<00:00,  2.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [09:48<00:00,  2.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:44<00:00,  2.38it/s]\n",
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 tr_disc_loss: 0.0108 val_disc_loss: 0.0043 tr_gen_loss: 0.0792 val_gen_loss: 0.0730, gen_stoi: 0.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [20:45<00:00,  1.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:51<00:00,  2.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [11:17<00:00,  1.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:42<00:00,  2.43it/s]\n",
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 tr_disc_loss: 0.0134 val_disc_loss: 0.0075 tr_gen_loss: 0.0137 val_gen_loss: 0.0041, gen_stoi: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [22:20<00:00,  1.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:53<00:00,  2.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [12:01<00:00,  1.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:43<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 tr_disc_loss: 0.0435 val_disc_loss: 0.0265 tr_gen_loss: 0.0675 val_gen_loss: 0.0582, gen_stoi: 0.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_sample = RandomSubsetDataset(train_ds, 1250, False)\n",
    "val_sample = RandomSubsetDataset(val_ds, 250, True)\n",
    "training.train_gan(gen, disc, gen_opt, disc_opt, train_sample, val_sample, 5, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), 'gen.pt')\n",
    "torch.save(disc.state_dict(), 'disc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5742/5742 [37:11<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_stoi = training.val_generator(gen, disc, test_ds, device, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0605 test STOI: 0.6512\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {test_loss:.4f} test STOI: {test_stoi:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторить результат из статьи не удалось. Улучшению может способствовать использование полной модели, а также большее время на обучение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
